<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ray&#39;s Blog on Ray&#39;s Blog</title>
    <link>https://leiheng.github.io/</link>
    <description>Recent content in Ray&#39;s Blog on Ray&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 02 Aug 2019 16:50:38 +0800</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Create an Object</title>
      <link>https://leiheng.github.io/posts/design-patterns/create-an-object/</link>
      <pubDate>Fri, 02 Aug 2019 16:50:38 +0800</pubDate>
      
      <guid>https://leiheng.github.io/posts/design-patterns/create-an-object/</guid>
      <description>

&lt;h2 id=&#34;builder-pattern&#34;&gt;Builder Pattern&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Getter
@Setter
public class BuilderSample {
  private String compo;
  private boolean flag;

  private BuilderSample(SampleBuild build) {
    this.compo = build.compo;
    this.flag = build.flag;
  }

  public static class SampleBuild {
    private String compo;
    private boolean flag = false;

    public BuilderSample build() {
      return new BuilderSample(this);
    }

    public SampleBuild setCompo(String compon) {
      this.compo = compon;
      return this;
    }

    public SampleBuild setFlag(boolean flag) {
      this.flag = flag;
      return this;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;OR&lt;/strong&gt; use &lt;code&gt;@Bulid&lt;/code&gt; ,everything is simple.&lt;/p&gt;

&lt;h2 id=&#34;factory-patterna&#34;&gt;Factory Patterna&lt;/h2&gt;

&lt;h2 id=&#34;singleton-pattern&#34;&gt;Singleton Pattern&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Best way to to implement a singleton pattern in Java is use &lt;code&gt;enum&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;a single-element enum type is the best way to implement a singleton. &amp;ndash;&amp;ldquo;Effective java&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public enum StatusEnum {
    SUCCESS(&amp;quot;9000&amp;quot;, &amp;quot;success&amp;quot;),
    private final String[] favoriteSongs =
        { &amp;quot;Hound Dog&amp;quot;, &amp;quot;Heartbreak Hotel&amp;quot; };
    public void printFavorites() {
        System.out.println(Arrays.toString(favoriteSongs));
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;double check create singleton&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class StatusEnum{
    private volatile static StatusEnum instance;
    private StatusEnum(){}
    public static StatusEnum getInstance(){
        if(instance == null){
            synchronized (StatusEnum.class){
                if (instance == null){
                    instance = new StatusEnum();
                }
            }
        }
        return instance;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;  ·End·  &lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Diff StatefulSet and Deployment</title>
      <link>https://leiheng.github.io/posts/k8s/diff-statefulset-and-deployment/</link>
      <pubDate>Fri, 02 Aug 2019 15:53:01 +0800</pubDate>
      
      <guid>https://leiheng.github.io/posts/k8s/diff-statefulset-and-deployment/</guid>
      <description>

&lt;ul&gt;
&lt;li&gt;Deployment - You specify a PersistentVolumeClaim that is shared by all pod replicas. In other words, shared volume.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The backing storage obviously must have ReadWriteMany or ReadOnlyMany accessMode if you have more than one replica pod.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;StatefulSet - You specify a volumeClaimTemplates so that each replica pod gets a unique PersistentVolumeClaim associated with it. In other words, no shared volume.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here, the backing storage can have ReadWriteOnce accessMode&lt;/p&gt;

&lt;p&gt;The deployment replicas pod share the same pv but stateful set not. Each statefulset pod has own pv-pvc.&lt;/p&gt;

&lt;p&gt;StatefulSet使用Headless服务来控制Pod的域名,那么这个pod的域名的FQDN为: &lt;code&gt;$(pod-name).$(service-name).$(namespace).svc.cluster.local&lt;/code&gt;. 其中,&lt;code&gt;cluster.local&lt;/code&gt;指的是集群的域名.&lt;/p&gt;

&lt;h2 id=&#34;statefulset&#34;&gt;StatefulSet&lt;/h2&gt;

&lt;hr /&gt;

&lt;p&gt;StatefulSet 控制的 pod 都是有状态的, 而像 deployment &amp;amp; replicaSet 这种就是 Stateless 无状态的. 具体表现为 StatefulSet 控制的pod并不分享pv - pvc.
&lt;del&gt;他们使用的&lt;code&gt;pv accessmode&lt;/code&gt; 都是 &lt;code&gt;ReadWriteOnce&lt;/code&gt;&lt;/del&gt;&lt;/p&gt;

&lt;h3 id=&#34;headless-service&#34;&gt;Headless Service&lt;/h3&gt;

&lt;p&gt;Headless service主要是用于分配DNS固定域名给那些 &lt;code&gt;StatefulSet&lt;/code&gt; 控制的 pod, 与这些 pod 通信主要是靠 DNS 而非 ip.&lt;/p&gt;

&lt;p&gt;作为headless service [&amp;hellip;.waiting]&lt;/p&gt;

&lt;h3 id=&#34;pv-pvc-volumeclaimtemple-about-statefulset&#34;&gt;pv &amp;amp; pvc &amp;amp; volumeClaimTemple about StatefulSet&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Static:
集群管理员创建多个PV。 它们携带可供集群用户使用的真实存储的详细信息。 它们存在于Kubernetes API中，可用于消费.&lt;/li&gt;
&lt;li&gt;Dynamic:
当管理员创建的静态PV都不匹配用户的PersistentVolumeClaim时，集群可能会尝试为PVC动态配置卷。 此配置基于StorageClasses：PVC必须请求一个类，并且管理员必须已创建并配置该类才能进行动态配置。 要求该类的声明有效地为自己禁用动态配置&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;so, 关于 StatefulSet 的 pv pvc binding 就是:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;自己手动创建 PV &amp;amp; PVC 并且注意好 pvc 的命名&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;StorageClass&lt;/code&gt; 动态 绑定&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;named-pvc&#34;&gt;named pvc&lt;/h4&gt;

&lt;p&gt;Create &lt;code&gt;volumeClaimTemplates&lt;/code&gt; like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;  volumeClaimTemplates:
  - metadata:
      name: &amp;quot;pvc-prefix&amp;quot;
    spec:
      accessModes:
      - &amp;quot;ReadWriteOnce&amp;quot;
      storageClassName: &amp;quot;storageName&amp;quot;
      resources:
        requests:
          storage: &amp;quot;1Gi&amp;quot;

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, your pvc must named &lt;code&gt;pvc-prefix-stsName-indx&lt;/code&gt; like &lt;code&gt;rabbitmq-infra-rabbitmq-0&lt;/code&gt;, statefulSet name is infra-rabbitmq. Otherwise, pod will be always &lt;code&gt;Pending&lt;/code&gt; because of cannot find mapping pvc.&lt;/p&gt;

&lt;h2 id=&#34;access-modes&#34;&gt;access modes&lt;/h2&gt;

&lt;hr /&gt;

&lt;p&gt;Kubernetes supports 3 kinds of access mode for persistent volume: ReadWriteOnce, ReadOnlyMany, ReadWriteMany.&lt;/p&gt;

&lt;p&gt;If a pod mounts a volume with &lt;strong&gt;ReadWriteOnce&lt;/strong&gt; access mode, no other pod can mount it.&lt;/p&gt;

&lt;p&gt;Most of our pod mounted the pv with  &lt;code&gt;ReadWriteMany&lt;/code&gt;. These pod share same resource.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ReadOnlyMany&lt;/code&gt; indicate this pv only can be read but no write right.&lt;/p&gt;

&lt;h3 id=&#34;refer&#34;&gt;REFER&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;pv access modes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/37649541/kubernetes-persistent-volume-accessmode&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;stackoverflow k8s pv accessmode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Dynamic Volume Provisioning - Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;  ·End·  &lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Install K8s The Hard Way</title>
      <link>https://leiheng.github.io/posts/k8s/install-k8s-hard-way/</link>
      <pubDate>Fri, 02 Aug 2019 15:20:37 +0800</pubDate>
      
      <guid>https://leiheng.github.io/posts/k8s/install-k8s-hard-way/</guid>
      <description>&lt;p&gt;Language is simple, show me your code.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# close swap
setenforce 0
sudo sed -i &#39;/SELINUX=enforcing/ s/enforcing/disabled/&#39; /etc/selinux/config
sudo swapoff -a  
sudo sed -i &#39;/ swap / s/^/#/g&#39; /etc/fstab

reboot

# set proxy
cat&amp;gt;&amp;gt;/etc/profile&amp;lt;&amp;lt;-EOF
export http_proxy=http://proxy.houston.hpecorp.net:8080
export https_proxy=http://proxy.houston.hpecorp.net:8080
EOF

source /etc/profile

mkdir /root/all-file
cd /root/all-file

# get docker and set proxy for docker
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh

mkdir -p /etc/systemd/system/docker.service.d
cat&amp;gt;&amp;gt;/etc/systemd/system/docker.service.d/http-proxy.conf&amp;lt;&amp;lt;-EOF
[Service]
Environment=&amp;quot;HTTP_PROXY=http://proxy-llb-hpm01.sgp.hp.com:8080&amp;quot; &amp;quot;HTTPS_PROXY=http://proxy-llb-hpm01.sgp.hp.com:8080&amp;quot; &amp;quot;NO_PROXY=localhost,127.0.0.1,.hp.com,.hpe.com,.hpeswlab.net,.hpecorp.net,.softwaregrp.net,.swinfra.net&amp;quot;
EOF

sudo systemctl daemon-reload
sudo systemctl restart docker

mkdir /root/all-file/ssl -p

cd ssl

# install cfssl
curl -LO https://pkg.cfssl.org/R1.2/cfssl_linux-amd64
chmod +x cfssl_linux-amd64
mv cfssl_linux-amd64 /usr/local/bin/cfssl

curl -LO https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64
chmod +x cfssljson_linux-amd64
mv cfssljson_linux-amd64 /usr/local/bin/cfssljson

curl -LO https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64
chmod +x cfssl-certinfo_linux-amd64
mv cfssl-certinfo_linux-amd64 /usr/local/bin/cfssl-certinfo

export PATH=/usr/local/bin:$PATH

# create ca-config
mkdir /root/ssl
cd /root/ssl
cfssl print-defaults config &amp;gt; config.json
cfssl print-defaults csr &amp;gt; csr.json

cat &amp;gt; ca-config.json &amp;lt;&amp;lt;EOF
{
  &amp;quot;signing&amp;quot;: {
    &amp;quot;default&amp;quot;: {
      &amp;quot;expiry&amp;quot;: &amp;quot;87600h&amp;quot;
    },
    &amp;quot;profiles&amp;quot;: {
      &amp;quot;kubernetes&amp;quot;: {
        &amp;quot;usages&amp;quot;: [
            &amp;quot;signing&amp;quot;,
            &amp;quot;key encipherment&amp;quot;,
            &amp;quot;server auth&amp;quot;,
            &amp;quot;client auth&amp;quot;
        ],
        &amp;quot;expiry&amp;quot;: &amp;quot;87600h&amp;quot;
      }
    }
  }
}
EOF

cat&amp;gt;&amp;gt;ca-csr.json&amp;lt;&amp;lt;-EOF
{
  &amp;quot;CN&amp;quot;: &amp;quot;kubernetes&amp;quot;,
  &amp;quot;key&amp;quot;: {
    &amp;quot;algo&amp;quot;: &amp;quot;rsa&amp;quot;,
    &amp;quot;size&amp;quot;: 2048
  },
  &amp;quot;names&amp;quot;: [
    {
      &amp;quot;C&amp;quot;: &amp;quot;CN&amp;quot;,
      &amp;quot;ST&amp;quot;: &amp;quot;ShangHai&amp;quot;,
      &amp;quot;L&amp;quot;: &amp;quot;ShangHai&amp;quot;,
      &amp;quot;O&amp;quot;: &amp;quot;k8s&amp;quot;,
      &amp;quot;OU&amp;quot;: &amp;quot;System&amp;quot;
    }
  ],
    &amp;quot;ca&amp;quot;: {
       &amp;quot;expiry&amp;quot;: &amp;quot;87600h&amp;quot;
    }
}
EOF

cfssl gencert -initca ca-csr.json | cfssljson -bare ca
ls ca*
# ca-config.json  ca.csr  ca-csr.json  ca-key.pem  ca.pem

cat&amp;gt;kubernetes-csr.json&amp;lt;&amp;lt;-EOF
{
    &amp;quot;CN&amp;quot;: &amp;quot;kubernetes&amp;quot;,
    &amp;quot;hosts&amp;quot;: [
      &amp;quot;127.0.0.1&amp;quot;,
      &amp;quot;15.119.88.180&amp;quot;,
      &amp;quot;15.119.88.181&amp;quot;,
      &amp;quot;15.119.88.182&amp;quot;,
      &amp;quot;10.254.0.1&amp;quot;,
      &amp;quot;kubernetes&amp;quot;,
      &amp;quot;kubernetes.default&amp;quot;,
      &amp;quot;kubernetes.default.svc&amp;quot;,
      &amp;quot;kubernetes.default.svc.cluster&amp;quot;,
      &amp;quot;kubernetes.default.svc.cluster.local&amp;quot;
    ],
    &amp;quot;key&amp;quot;: {
        &amp;quot;algo&amp;quot;: &amp;quot;rsa&amp;quot;,
        &amp;quot;size&amp;quot;: 2048
    },
    &amp;quot;names&amp;quot;: [
        {
            &amp;quot;C&amp;quot;: &amp;quot;CN&amp;quot;,
            &amp;quot;ST&amp;quot;: &amp;quot;ShangHai&amp;quot;,
            &amp;quot;L&amp;quot;: &amp;quot;ShangHai&amp;quot;,
            &amp;quot;O&amp;quot;: &amp;quot;k8s&amp;quot;,
            &amp;quot;OU&amp;quot;: &amp;quot;System&amp;quot;
        }
    ]
}
EOF


cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kubernetes-csr.json | cfssljson -bare kubernetes
ls kubernetes*

cat&amp;gt;&amp;gt;admin-csr.json&amp;lt;&amp;lt;-EOF
{
  &amp;quot;CN&amp;quot;: &amp;quot;admin&amp;quot;,
  &amp;quot;hosts&amp;quot;: [],
  &amp;quot;key&amp;quot;: {
    &amp;quot;algo&amp;quot;: &amp;quot;rsa&amp;quot;,
    &amp;quot;size&amp;quot;: 2048
  },
  &amp;quot;names&amp;quot;: [
    {
      &amp;quot;C&amp;quot;: &amp;quot;CN&amp;quot;,
      &amp;quot;ST&amp;quot;: &amp;quot;ShangHai&amp;quot;,
      &amp;quot;L&amp;quot;: &amp;quot;ShangHai&amp;quot;,
      &amp;quot;O&amp;quot;: &amp;quot;system:masters&amp;quot;,
      &amp;quot;OU&amp;quot;: &amp;quot;System&amp;quot;
    }
  ]
}
EOF


cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes admin-csr.json | cfssljson -bare admin

cat&amp;gt;kube-proxy-csr.json&amp;lt;&amp;lt;-EOF
{
  &amp;quot;CN&amp;quot;: &amp;quot;system:kube-proxy&amp;quot;,
  &amp;quot;hosts&amp;quot;: [],
  &amp;quot;key&amp;quot;: {
    &amp;quot;algo&amp;quot;: &amp;quot;rsa&amp;quot;,
    &amp;quot;size&amp;quot;: 2048
  },
  &amp;quot;names&amp;quot;: [
    {
      &amp;quot;C&amp;quot;: &amp;quot;CN&amp;quot;,
      &amp;quot;ST&amp;quot;: &amp;quot;ShangHai&amp;quot;,
      &amp;quot;L&amp;quot;: &amp;quot;Shanghai&amp;quot;,
      &amp;quot;O&amp;quot;: &amp;quot;k8s&amp;quot;,
      &amp;quot;OU&amp;quot;: &amp;quot;System&amp;quot;
    }
  ]
}
EOF

cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes  kube-proxy-csr.json | cfssljson -bare kube-proxy
ls kube-proxy*

openssl x509  -noout -text -in  kubernetes.pem
cfssl-certinfo -cert kubernetes.pem

mkdir -p /etc/kubernetes/ssl
cp *.pem /etc/kubernetes/ssl

cd /root/all-file

curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.11.2/bin/linux/amd64/kubectl
cp kubectl /usr/bin/
chmod a+x /usr/bin/kube*

export KUBE_APISERVER=&amp;quot;https://15.119.88.180:6443&amp;quot;

echo $KUBE_APISERVER

kubectl config set-cluster kubernetes \
  --certificate-authority=/etc/kubernetes/ssl/ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER}

kubectl config set-credentials admin \
  --client-certificate=/etc/kubernetes/ssl/admin.pem \
  --embed-certs=true \
  --client-key=/etc/kubernetes/ssl/admin-key.pem

kubectl config set-context kubernetes \
  --cluster=kubernetes \
  --user=admin

kubectl config use-context kubernetes

cd /root/ssl

export BOOTSTRAP_TOKEN=$(head -c 16 /dev/urandom | od -An -t x | tr -d &#39; &#39;)
cat &amp;gt; token.csv &amp;lt;&amp;lt;EOF
${BOOTSTRAP_TOKEN},kubelet-bootstrap,10001,&amp;quot;system:kubelet-bootstrap&amp;quot;
EOF

cat token.csv
cp /root/ssl/token.csv /etc/kubernetes/

cd /etc/kubernetes
export KUBE_APISERVER=&amp;quot;https://15.119.88.180:6443&amp;quot;

kubectl config set-cluster kubernetes \
  --certificate-authority=/etc/kubernetes/ssl/ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=bootstrap.kubeconfig

kubectl config set-credentials kubelet-bootstrap \
  --token=${BOOTSTRAP_TOKEN} \
  --kubeconfig=bootstrap.kubeconfig

kubectl config set-context default \
  --cluster=kubernetes \
  --user=kubelet-bootstrap \
  --kubeconfig=bootstrap.kubeconfig

kubectl config use-context default --kubeconfig=bootstrap.kubeconfig


export KUBE_APISERVER=&amp;quot;https://15.119.88.180:6443&amp;quot;

kubectl config set-cluster kubernetes \
  --certificate-authority=/etc/kubernetes/ssl/ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=kube-proxy.kubeconfig

kubectl config set-credentials kube-proxy \
  --client-certificate=/etc/kubernetes/ssl/kube-proxy.pem \
  --client-key=/etc/kubernetes/ssl/kube-proxy-key.pem \
  --embed-certs=true \
  --kubeconfig=kube-proxy.kubeconfig

kubectl config set-context default \
  --cluster=kubernetes \
  --user=kube-proxy \
  --kubeconfig=kube-proxy.kubeconfig

kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig



# 各个节点上的/etc/kubernetes/要保持同步
# sftp root@shc-sma-cd180.hpeswlab.net
# get -r /etc/kubernetes/ /etc/kubernetes/
# 上面的操作就只是在master节点上操作，在node节点上只要把这些证书拷过去


cd /root/all-file

curl https://github.com/coreos/etcd/releases/download/v3.3.9/etcd-v3.3.9-linux-amd64.tar.gz -LO
tar -xvf etcd-v3.3.9-linux-amd64.tar.gz
mv etcd-v3.3.9-linux-amd64/etcd* /usr/local/bin

mkdir /var/lib/etcd
mkdir /etc/etcd

vim /usr/lib/systemd/system/etcd.service

[Unit]
Description=Etcd Server
After=network.target
After=network-online.target
Wants=network-online.target
Documentation=https://github.com/coreos

[Service]
Type=notify
WorkingDirectory=/var/lib/etcd/
EnvironmentFile=-/etc/etcd/etcd.conf
ExecStart=/usr/local/bin/etcd \
  --name ${ETCD_NAME} \
  --cert-file=/etc/kubernetes/ssl/kubernetes.pem \
  --key-file=/etc/kubernetes/ssl/kubernetes-key.pem \
  --peer-cert-file=/etc/kubernetes/ssl/kubernetes.pem \
  --peer-key-file=/etc/kubernetes/ssl/kubernetes-key.pem \
  --trusted-ca-file=/etc/kubernetes/ssl/ca.pem \
  --peer-trusted-ca-file=/etc/kubernetes/ssl/ca.pem \
  --initial-advertise-peer-urls ${ETCD_INITIAL_ADVERTISE_PEER_URLS} \
  --listen-peer-urls ${ETCD_LISTEN_PEER_URLS} \
  --listen-client-urls ${ETCD_LISTEN_CLIENT_URLS},http://127.0.0.1:2379 \
  --advertise-client-urls ${ETCD_ADVERTISE_CLIENT_URLS} \
  --initial-cluster-token ${ETCD_INITIAL_CLUSTER_TOKEN} \
  --initial-cluster infra1=https://15.119.88.180:2380,infra2=https://15.119.88.181:2380,infra3=https://15.119.88.182:2380 \
  --initial-cluster-state new \
  --data-dir=${ETCD_DATA_DIR}
Restart=on-failure
RestartSec=5
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target

cat&amp;gt;/etc/etcd/etcd.conf&amp;lt;&amp;lt;-EOF
# [member]
ETCD_NAME=infra1
ETCD_DATA_DIR=&amp;quot;/var/lib/etcd&amp;quot;
ETCD_LISTEN_PEER_URLS=&amp;quot;https://15.119.88.180:2380&amp;quot;
ETCD_LISTEN_CLIENT_URLS=&amp;quot;https://15.119.88.180:2379&amp;quot;

#[cluster]
ETCD_INITIAL_ADVERTISE_PEER_URLS=&amp;quot;https://15.119.88.180:2380&amp;quot;
ETCD_INITIAL_CLUSTER_TOKEN=&amp;quot;etcd-cluster&amp;quot;
ETCD_ADVERTISE_CLIENT_URLS=&amp;quot;https://15.119.88.180:2379&amp;quot;
EOF

# ==============

mkdir /etc/etcd
cat&amp;gt;/etc/etcd/etcd.conf&amp;lt;&amp;lt;-EOF
# [member]
ETCD_NAME=infra2
ETCD_DATA_DIR=&amp;quot;/var/lib/etcd&amp;quot;
ETCD_LISTEN_PEER_URLS=&amp;quot;https://15.119.88.181:2380&amp;quot;
ETCD_LISTEN_CLIENT_URLS=&amp;quot;https://15.119.88.181:2379&amp;quot;

#[cluster]
ETCD_INITIAL_ADVERTISE_PEER_URLS=&amp;quot;https://15.119.88.181:2380&amp;quot;
ETCD_INITIAL_CLUSTER_TOKEN=&amp;quot;etcd-cluster&amp;quot;
ETCD_ADVERTISE_CLIENT_URLS=&amp;quot;https://15.119.88.181:2379&amp;quot;
EOF

mkdir /etc/etcd
cat&amp;gt;/etc/etcd/etcd.conf&amp;lt;&amp;lt;-EOF
# [member]
ETCD_NAME=infra3
ETCD_DATA_DIR=&amp;quot;/var/lib/etcd&amp;quot;
ETCD_LISTEN_PEER_URLS=&amp;quot;https://15.119.88.182:2380&amp;quot;
ETCD_LISTEN_CLIENT_URLS=&amp;quot;https://15.119.88.182:2379&amp;quot;

#[cluster]
ETCD_INITIAL_ADVERTISE_PEER_URLS=&amp;quot;https://15.119.88.182:2380&amp;quot;
ETCD_INITIAL_CLUSTER_TOKEN=&amp;quot;etcd-cluster&amp;quot;
ETCD_ADVERTISE_CLIENT_URLS=&amp;quot;https://15.119.88.182:2379&amp;quot;
EOF


# =========================

systemctl daemon-reload
systemctl enable etcd
systemctl start etcd
systemctl status etcd

etcdctl \
  --ca-file=/etc/kubernetes/ssl/ca.pem \
  --cert-file=/etc/kubernetes/ssl/kubernetes.pem \
  --key-file=/etc/kubernetes/ssl/kubernetes-key.pem \
  cluster-health

 显示最后一行cluster is healthy etcd 就安装成功


cd /root/all-file

curl https://github.com/kubernetes/kubernetes/releases/download/v1.11.2/kubernetes.tar.gz -OL
tar -xzvf kubernetes.tar.gz
cd kubernetes
./cluster/get-kube-binaries.sh
cd server
tar -xzvf kubernetes-server-linux-amd64.tar.gz
cd kubernetes
tar -xzvf  kubernetes-src.tar.gz
cp -r server/bin/{kube-apiserver,kube-controller-manager,kube-scheduler,kubectl,kube-proxy,kubelet} /usr/local/bin/

cat&amp;gt;/etc/kubernetes/config&amp;lt;&amp;lt;-EOF
###
# kubernetes system config
#
# The following values are used to configure various aspects of all
# kubernetes services, including
#
#   kube-apiserver.service
#   kube-controller-manager.service
#   kube-scheduler.service
#   kubelet.service
#   kube-proxy.service
# logging to stderr means we get it in the systemd journal
KUBE_LOGTOSTDERR=&amp;quot;--logtostderr=true&amp;quot;

# journal message level, 0 is debug
KUBE_LOG_LEVEL=&amp;quot;--v=0&amp;quot;

# Should this cluster be allowed to run privileged docker containers
KUBE_ALLOW_PRIV=&amp;quot;--allow-privileged=true&amp;quot;

# How the controller-manager, scheduler, and proxy find the apiserver
#KUBE_MASTER=&amp;quot;--master=http://shc-sma-cd180.hpeswlab.net&amp;quot;
KUBE_MASTER=&amp;quot;--master=http://15.119.88.180:8080&amp;quot;
EOF

vim /usr/lib/systemd/system/kube-apiserver.service

[Unit]
Description=Kubernetes API Service
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=network.target
After=etcd.service

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/apiserver
ExecStart=/usr/local/bin/kube-apiserver \
        $KUBE_LOGTOSTDERR \
        $KUBE_LOG_LEVEL \
        $KUBE_ETCD_SERVERS \
        $KUBE_API_ADDRESS \
        $KUBE_API_PORT \
        $KUBELET_PORT \
        $KUBE_ALLOW_PRIV \
        $KUBE_SERVICE_ADDRESSES \
        $KUBE_ADMISSION_CONTROL \
        $KUBE_API_ARGS
Restart=on-failure
Type=notify
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target


cat&amp;gt;/etc/kubernetes/apiserver&amp;lt;&amp;lt;-EOF
###
## kubernetes system config
##
## The following values are used to configure the kube-apiserver
##
#
## The address on the local server to listen to.
#KUBE_API_ADDRESS=&amp;quot;--insecure-bind-address=shc-sma-cd180.hpeswlab.net&amp;quot;
KUBE_API_ADDRESS=&amp;quot;--advertise-address=15.119.88.180 --bind-address=15.119.88.180 --insecure-bind-address=15.119.88.180&amp;quot;
#
## The port on the local server to listen on.
#KUBE_API_PORT=&amp;quot;--port=8080&amp;quot;
#
## Port minions listen on
#KUBELET_PORT=&amp;quot;--kubelet-port=10250&amp;quot;
#
## Comma separated list of nodes in the etcd cluster
KUBE_ETCD_SERVERS=&amp;quot;--etcd-servers=https://15.119.88.180:2379,https://15.119.88.181:2379,https://15.119.88.182:2379&amp;quot;
#
## Address range to use for services
KUBE_SERVICE_ADDRESSES=&amp;quot;--service-cluster-ip-range=10.254.0.0/16&amp;quot;
#
## default admission control policies
KUBE_ADMISSION_CONTROL=&amp;quot;--admission-control=ServiceAccount,NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota&amp;quot;
#
## Add your own!
KUBE_API_ARGS=&amp;quot;--authorization-mode=Node,RBAC --runtime-config=rbac.authorization.k8s.io/v1beta1 --kubelet-https=true --enable-bootstrap-token-auth --token-auth-file=/etc/kubernetes/token.csv --service-node-port-range=30000-32767 --tls-cert-file=/etc/kubernetes/ssl/kubernetes.pem --tls-private-key-file=/etc/kubernetes/ssl/kubernetes-key.pem --client-ca-file=/etc/kubernetes/ssl/ca.pem --service-account-key-file=/etc/kubernetes/ssl/ca-key.pem --etcd-cafile=/etc/kubernetes/ssl/ca.pem --etcd-certfile=/etc/kubernetes/ssl/kubernetes.pem --etcd-keyfile=/etc/kubernetes/ssl/kubernetes-key.pem --enable-swagger-ui=true --apiserver-count=3 --audit-log-maxage=30 --audit-log-maxbackup=3 --audit-log-maxsize=100 --audit-log-path=/var/lib/audit.log --event-ttl=1h&amp;quot;
EOF

systemctl daemon-reload
systemctl enable kube-apiserver
systemctl start kube-apiserver
systemctl status kube-apiserver

cat&amp;gt;/etc/kubernetes/controller-manager&amp;lt;&amp;lt;-EOF
###
# The following values are used to configure the kubernetes controller-manager

# defaults from config and apiserver should be adequate

# Add your own!
KUBE_CONTROLLER_MANAGER_ARGS=&amp;quot;--address=127.0.0.1 --service-cluster-ip-range=10.254.0.0/16 --cluster-name=kubernetes --cluster-signing-cert-file=/etc/kubernetes/ssl/ca.pem --cluster-signing-key-file=/etc/kubernetes/ssl/ca-key.pem  --service-account-private-key-file=/etc/kubernetes/ssl/ca-key.pem --root-ca-file=/etc/kubernetes/ssl/ca.pem --leader-elect=true&amp;quot;
EOF

vim /usr/lib/systemd/system/kube-controller-manager.service

[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/controller-manager
ExecStart=/usr/local/bin/kube-controller-manager \
        $KUBE_LOGTOSTDERR \
        $KUBE_LOG_LEVEL \
        $KUBE_MASTER \
        $KUBE_CONTROLLER_MANAGER_ARGS
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target


systemctl daemon-reload
systemctl enable kube-controller-manager
systemctl start kube-controller-manager
systemctl status kube-controller-manager


cat&amp;gt;/etc/kubernetes/scheduler&amp;lt;&amp;lt;-EOF
###
# kubernetes scheduler config

# default config should be adequate

# Add your own!
KUBE_SCHEDULER_ARGS=&amp;quot;--leader-elect=true --address=127.0.0.1&amp;quot;
EOF


vim /usr/lib/systemd/system/kube-scheduler.service

[Unit]
Description=Kubernetes Scheduler Plugin
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/scheduler
ExecStart=/usr/local/bin/kube-scheduler \
            $KUBE_LOGTOSTDERR \
            $KUBE_LOG_LEVEL \
            $KUBE_MASTER \
            $KUBE_SCHEDULER_ARGS
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target

systemctl daemon-reload
systemctl enable kube-scheduler
systemctl start kube-scheduler
systemctl status kube-scheduler

========================
kubectl get componentstatuses


============install flannel=========

yum install -y flannel

vim /usr/lib/systemd/system/flanneld.service

[Unit]
Description=Flanneld overlay address etcd agent
After=network.target
After=network-online.target
Wants=network-online.target
After=etcd.service
Before=docker.service

[Service]
Type=notify
EnvironmentFile=/etc/sysconfig/flanneld
EnvironmentFile=-/etc/sysconfig/docker-network
ExecStart=/usr/bin/flanneld-start \
  -etcd-endpoints=${FLANNEL_ETCD_ENDPOINTS} \
  -etcd-prefix=${FLANNEL_ETCD_PREFIX} \
  $FLANNEL_OPTIONS
ExecStartPost=/usr/libexec/flannel/mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/docker
Restart=on-failure

[Install]
WantedBy=multi-user.target

RequiredBy=docker.service

cat&amp;gt;/etc/sysconfig/flanneld&amp;lt;&amp;lt;-EOF
# Flanneld configuration options  

# etcd url location.  Point this to the server where etcd runs
FLANNEL_ETCD_ENDPOINTS=&amp;quot;https://15.119.88.180:2379,https://15.119.88.181:2379,https://15.119.88.182:2379&amp;quot;

# etcd config key.  This is the configuration key that flannel queries
# For address range assignment
FLANNEL_ETCD_PREFIX=&amp;quot;/kube-centos/network&amp;quot;

# Any additional options that you want to pass
FLANNEL_OPTIONS=&amp;quot;-etcd-cafile=/etc/kubernetes/ssl/ca.pem -etcd-certfile=/etc/kubernetes/ssl/kubernetes.pem -etcd-keyfile=/etc/kubernetes/ssl/kubernetes-key.pem&amp;quot;
EOF

cat /usr/lib/systemd/system/flanneld.service


etcdctl --endpoints=https://15.119.88.180:2379,https://15.119.88.181:2379,https://15.119.88.182:2379 \
  --ca-file=/etc/kubernetes/ssl/ca.pem \
  --cert-file=/etc/kubernetes/ssl/kubernetes.pem \
  --key-file=/etc/kubernetes/ssl/kubernetes-key.pem \
  mkdir /kube-centos/network
etcdctl --endpoints=https://15.119.88.180:2379,https://15.119.88.181:2379,https://15.119.88.182:2379 \
  --ca-file=/etc/kubernetes/ssl/ca.pem \
  --cert-file=/etc/kubernetes/ssl/kubernetes.pem \
  --key-file=/etc/kubernetes/ssl/kubernetes-key.pem \
  mk /kube-centos/network/config &#39;{&amp;quot;Network&amp;quot;:&amp;quot;172.30.0.0/16&amp;quot;,&amp;quot;SubnetLen&amp;quot;:24,&amp;quot;Backend&amp;quot;:{&amp;quot;Type&amp;quot;:&amp;quot;vxlan&amp;quot;}}&#39;

systemctl daemon-reload
systemctl enable flanneld
systemctl start flanneld
systemctl status flanneld


check：

etcdctl --endpoints=${ETCD_ENDPOINTS} \
  --ca-file=/etc/kubernetes/ssl/ca.pem \
  --cert-file=/etc/kubernetes/ssl/kubernetes.pem \
  --key-file=/etc/kubernetes/ssl/kubernetes-key.pem \
  ls /kube-centos/network/subnets
/kube-centos/network/subnets/172.30.14.0-24
/kube-centos/network/subnets/172.30.38.0-24
/kube-centos/network/subnets/172.30.46.0-24

etcdctl --endpoints=${ETCD_ENDPOINTS} \
  --ca-file=/etc/kubernetes/ssl/ca.pem \
  --cert-file=/etc/kubernetes/ssl/kubernetes.pem \
  --key-file=/etc/kubernetes/ssl/kubernetes-key.pem \
  get /kube-centos/network/config
{ &amp;quot;Network&amp;quot;: &amp;quot;172.30.0.0/16&amp;quot;, &amp;quot;SubnetLen&amp;quot;: 24, &amp;quot;Backend&amp;quot;: { &amp;quot;Type&amp;quot;: &amp;quot;vxlan&amp;quot; } }

etcdctl --endpoints=${ETCD_ENDPOINTS} \
  --ca-file=/etc/kubernetes/ssl/ca.pem \
  --cert-file=/etc/kubernetes/ssl/kubernetes.pem \
  --key-file=/etc/kubernetes/ssl/kubernetes-key.pem \
  get /kube-centos/network/subnets/172.30.14.0-24
{&amp;quot;PublicIP&amp;quot;:&amp;quot;172.20.0.114&amp;quot;,&amp;quot;BackendType&amp;quot;:&amp;quot;vxlan&amp;quot;,&amp;quot;BackendData&amp;quot;:{&amp;quot;VtepMAC&amp;quot;:&amp;quot;56:27:7d:1c:08:22&amp;quot;}}

etcdctl --endpoints=${ETCD_ENDPOINTS} \
  --ca-file=/etc/kubernetes/ssl/ca.pem \
  --cert-file=/etc/kubernetes/ssl/kubernetes.pem \
  --key-file=/etc/kubernetes/ssl/kubernetes-key.pem \
  get /kube-centos/network/subnets/172.30.38.0-24
{&amp;quot;PublicIP&amp;quot;:&amp;quot;172.20.0.115&amp;quot;,&amp;quot;BackendType&amp;quot;:&amp;quot;vxlan&amp;quot;,&amp;quot;BackendData&amp;quot;:{&amp;quot;VtepMAC&amp;quot;:&amp;quot;12:82:83:59:cf:b8&amp;quot;}}

etcdctl --endpoints=${ETCD_ENDPOINTS} \
  --ca-file=/etc/kubernetes/ssl/ca.pem \
  --cert-file=/etc/kubernetes/ssl/kubernetes.pem \
  --key-file=/etc/kubernetes/ssl/kubernetes-key.pem \
  get /kube-centos/network/subnets/172.30.46.0-24
{&amp;quot;PublicIP&amp;quot;:&amp;quot;172.20.0.113&amp;quot;,&amp;quot;BackendType&amp;quot;:&amp;quot;vxlan&amp;quot;,&amp;quot;BackendData&amp;quot;:{&amp;quot;VtepMAC&amp;quot;:&amp;quot;e6:b2:fd:f6:66:96&amp;quot;}}


ls /etc/kubernetes/ssl
# admin-key.pem  admin.pem  ca-key.pem  ca.pem  kube-proxy-key.pem  kube-proxy.pem  kubernetes-key.pem  kubernetes.pem
ls /etc/kubernetes/
# apiserver  bootstrap.kubeconfig  config  controller-manager  kubelet  kube-proxy.kubeconfig  proxy  scheduler  ssl  token.csv


vim /usr/lib/systemd/system/docker.service

# add below under [service]

EnvironmentFile=-/run/flannel/docker
EnvironmentFile=-/run/docker_opts.env
EnvironmentFile=-/run/flannel/subnet.env
EnvironmentFile=-/etc/sysconfig/docker
EnvironmentFile=-/etc/sysconfig/docker-storage
EnvironmentFile=-/etc/sysconfig/docker-network
EnvironmentFile=-/run/docker_opts.env

ExecStart=/usr/bin/dockerd \
    --exec-opt native.cgroupdriver=systemd

systemctl daemon-reload
systemctl restart docker

cd /etc/kubernetes
kubectl create clusterrolebinding kubelet-bootstrap \
  --clusterrole=system:node-bootstrapper \
  --user=kubelet-bootstrap

# download kubelet and move to /usr/local/bin
# master上面在安装kubectl的时候就已经cp过去了,node节点参照master节点
# master 上面需要创建kubelet and kube-proxy service
# node上面还需下载kube client

curl 

# config kubelet

mkdir -p /var/lib/kubelet

vim /usr/lib/systemd/system/kubelet.service

[Unit]
Description=Kubernetes Kubelet Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=docker.service
Requires=docker.service

[Service]
WorkingDirectory=/var/lib/kubelet
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/kubelet
ExecStart=/usr/local/bin/kubelet \
            $KUBE_LOGTOSTDERR \
            $KUBE_LOG_LEVEL \
            $KUBELET_API_SERVER \
            $KUBELET_ADDRESS \
            $KUBELET_PORT \
            $KUBELET_HOSTNAME \
            $KUBE_ALLOW_PRIV \
            $KUBELET_POD_INFRA_CONTAINER \
            $KUBELET_ARGS
Restart=on-failure

[Install]
WantedBy=multi-user.target


cat&amp;gt;/etc/kubernetes/kubelet&amp;lt;&amp;lt;-EOF
###
## kubernetes kubelet (minion) config
#
## The address for the info server to serve on (set to 0.0.0.0 or &amp;quot;&amp;quot; for all interfaces)
KUBELET_ADDRESS=&amp;quot;--address=15.119.88.180&amp;quot;
#
## The port for the info server to serve on
#KUBELET_PORT=&amp;quot;--port=10250&amp;quot;
#
## You may leave this blank to use the actual hostname
KUBELET_HOSTNAME=&amp;quot;--hostname-override=15.119.88.180&amp;quot;
#
## location of the api-server
## COMMENT THIS ON KUBERNETES 1.8+
# KUBELET_API_SERVER=&amp;quot;--api-servers=http://15.119.88.180:8080&amp;quot;
#
## pod infrastructure container
KUBELET_POD_INFRA_CONTAINER=&amp;quot;--pod-infra-container-image=gcr.io/google_containers/pause-amd64:3.0&amp;quot;
#
## Add your own!
KUBELET_ARGS=&amp;quot;--cgroup-driver=systemd --runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice --cluster-dns=10.254.0.2 --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig --kubeconfig=/etc/kubernetes/kubelet.kubeconfig --cert-dir=/etc/kubernetes/ssl --cluster-domain=cluster.local --hairpin-mode promiscuous-bridge --serialize-image-pulls=false&amp;quot;
EOF


cat&amp;gt;/etc/kubernetes/kubelet&amp;lt;&amp;lt;-EOF
###
## kubernetes kubelet (minion) config
#
## The address for the info server to serve on (set to 0.0.0.0 or &amp;quot;&amp;quot; for all interfaces)
KUBELET_ADDRESS=&amp;quot;--address=15.119.88.181&amp;quot;
#
## The port for the info server to serve on
#KUBELET_PORT=&amp;quot;--port=10250&amp;quot;
#
## You may leave this blank to use the actual hostname
KUBELET_HOSTNAME=&amp;quot;--hostname-override=15.119.88.181&amp;quot;
#
## location of the api-server
## COMMENT THIS ON KUBERNETES 1.8+
# KUBELET_API_SERVER=&amp;quot;--api-servers=http://15.119.88.181:8080&amp;quot;
#
## pod infrastructure container
KUBELET_POD_INFRA_CONTAINER=&amp;quot;--pod-infra-container-image=gcr.io/google_containers/pause-amd64:3.0&amp;quot;
#
## Add your own!
KUBELET_ARGS=&amp;quot;--cgroup-driver=systemd --runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice --cluster-dns=10.254.0.2 --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig --kubeconfig=/etc/kubernetes/kubelet.kubeconfig --cert-dir=/etc/kubernetes/ssl --cluster-domain=cluster.local --hairpin-mode promiscuous-bridge --serialize-image-pulls=false&amp;quot;
EOF

==============
cat&amp;gt;/etc/kubernetes/kubelet&amp;lt;&amp;lt;-EOF
###
## kubernetes kubelet (minion) config
#
## The address for the info server to serve on (set to 0.0.0.0 or &amp;quot;&amp;quot; for all interfaces)
KUBELET_ADDRESS=&amp;quot;--address=15.119.88.182&amp;quot;
#
## The port for the info server to serve on
#KUBELET_PORT=&amp;quot;--port=10250&amp;quot;
#
## You may leave this blank to use the actual hostname
KUBELET_HOSTNAME=&amp;quot;--hostname-override=15.119.88.182&amp;quot;
#
## location of the api-server
## COMMENT THIS ON KUBERNETES 1.8+
# KUBELET_API_SERVER=&amp;quot;--api-servers=http://15.119.88.182:8080&amp;quot;
#
## pod infrastructure container
KUBELET_POD_INFRA_CONTAINER=&amp;quot;--pod-infra-container-image=gcr.io/google_containers/pause-amd64:3.0&amp;quot;
#
## Add your own!
KUBELET_ARGS=&amp;quot;--cgroup-driver=systemd --runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice --cluster-dns=10.254.0.2 --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig --kubeconfig=/etc/kubernetes/kubelet.kubeconfig --cert-dir=/etc/kubernetes/ssl --cluster-domain=cluster.local --hairpin-mode promiscuous-bridge --serialize-image-pulls=false&amp;quot;
EOF

scp root@shc-sma-cd180.hpeswlab.net:/etc/kubernetes/kubelet.kubeconfig /etc/kubernetes/kubelet.kubeconfig
# master 上的kubelet.kubeconfig是~/.kube/config 
 # cp ~/.kube/config /etc/kubernetes/kubelet.kubeconfig

systemctl daemon-reload
systemctl enable kubelet
systemctl start kubelet
systemctl status kubelet



vim /usr/lib/systemd/system/kube-proxy.service

[Unit]
Description=Kubernetes Kube-Proxy Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=network.target

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/proxy
ExecStart=/usr/local/bin/kube-proxy \
        $KUBE_LOGTOSTDERR \
        $KUBE_LOG_LEVEL \
        $KUBE_MASTER \
        $KUBE_PROXY_ARGS
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target

cat&amp;gt;/etc/kubernetes/proxy&amp;lt;&amp;lt;-EOF
###
# kubernetes proxy config

# default config should be adequate

# Add your own!
KUBE_PROXY_ARGS=&amp;quot;--bind-address=15.119.88.180 --hostname-override=15.119.88.180 --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig --cluster-cidr=10.254.0.0/16&amp;quot;
EOF

============
cat&amp;gt;/etc/kubernetes/proxy&amp;lt;&amp;lt;-EOF
###
# kubernetes proxy config

# default config should be adequate

# Add your own!
KUBE_PROXY_ARGS=&amp;quot;--bind-address=15.119.88.181 --hostname-override=15.119.88.181 --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig --cluster-cidr=10.254.0.0/16&amp;quot;
EOF

===============
cat&amp;gt;/etc/kubernetes/proxy&amp;lt;&amp;lt;-EOF
###
# kubernetes proxy config

# default config should be adequate

# Add your own!
KUBE_PROXY_ARGS=&amp;quot;--bind-address=15.119.88.182 --hostname-override=15.119.88.182 --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig --cluster-cidr=10.254.0.0/16&amp;quot;
EOF

systemctl daemon-reload
systemctl enable kube-proxy
systemctl start kube-proxy
systemctl status kube-proxy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;  ·End·  &lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Code Style</title>
      <link>https://leiheng.github.io/posts/java/code-style/</link>
      <pubDate>Thu, 01 Aug 2019 19:25:47 +0800</pubDate>
      
      <guid>https://leiheng.github.io/posts/java/code-style/</guid>
      <description>

&lt;h2 id=&#34;到-resource-文件夹里面拿文件&#34;&gt;到 resource 文件夹里面拿文件&lt;/h2&gt;

&lt;hr /&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;String response = Resources.toString(Resources.getResource(&amp;quot;response.json&amp;quot;), Charsets.UTF_8);
// bytes:
Resources.asByteSource(Resources.getResource(&amp;quot;datain_100000.log&amp;quot;).toURI().toURL()).openBufferedStream();

// Guava:
  public static URL getResource(String resourceName) {
    ClassLoader loader =
        MoreObjects.firstNonNull(
            Thread.currentThread().getContextClassLoader(), Resources.class.getClassLoader());
    URL url = loader.getResource(resourceName);
    checkArgument(url != null, &amp;quot;resource %s not found.&amp;quot;, resourceName);
    return url;
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;get-env-in-springboot&#34;&gt;get env in SpringBoot&lt;/h2&gt;

&lt;hr /&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;// define properties in application.yaml like:
project:
  service:
    name: smarta-installer
    feature:
      mgmt:
        job-setting:
          job-retry-time: ${JOB_RETRY_TIME:100}
          job-interval-time: ${JOB_INTERVAL_TIME:60}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;then, create Bean:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Data
@ConfigurationProperties(prefix = &amp;quot;project.service.feature.mgmt&amp;quot;)
public class AppConfigProperties {
	private ScaleJobSetting JobSetting;

	@Data
	public static class JobSetting {
		private long jobRetryTime = 100;
		private long jobIntervalTime = 60;
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;now, have fun.&lt;/p&gt;

&lt;h2 id=&#34;try-with-resource&#34;&gt;try with resource&lt;/h2&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;能&lt;code&gt;try with resource&lt;/code&gt;的类必须继承&lt;code&gt;AutoCloseable&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;流式处理I/O&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void queryEncode2() throws Exception {
   AciServerDetails aciServerDetails = getServerDetails(Constants.idolHost, Constants.idolQueryPort, Constants.idolOemKey);
   try (
           InputStream inputStream = Resources.asByteSource(Resources.getResource(&amp;quot;datain_100000.log&amp;quot;).toURI().toURL()).openBufferedStream();
           BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inputStream));
           OutputStream outputStream = Files.asByteSink(new File(&amp;quot;output/querys.txt&amp;quot;)).openBufferedStream();
   ) {
     Flux.fromStream(bufferedReader.lines())
             .subscribe( query -&amp;gt; {
                       try {
                         log.info(&amp;quot;query is, {}&amp;quot;, query);
                         outputStream.write(SimpleQuery.encode(aciServerDetails, query).getBytes());
                         outputStream.write(&amp;quot;\n&amp;quot;.getBytes());
                       } catch (Exception e) {
                         log.info(&amp;quot;error query is, {}&amp;quot;, query);
                         log.error(&amp;quot;&amp;quot;, e);
                       }
                     }
             );
   }
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;or&lt;/strong&gt; vertx.fileSytem()&lt;/p&gt;

&lt;h3 id=&#34;refer&#34;&gt;refer&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;java-string-immutable&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;java-string-immutable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.baeldung.com/java-immutable-object&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;java-immutable-object&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;java-string-pool&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;java-string-pool&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Https for Harbor</title>
      <link>https://leiheng.github.io/posts/docker/https-for-harbor/</link>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://leiheng.github.io/posts/docker/https-for-harbor/</guid>
      <description>

&lt;h2 id=&#34;https&#34;&gt;https&lt;/h2&gt;

&lt;p&gt;Exercise install Harbor and configure https.&lt;/p&gt;

&lt;h3 id=&#34;prepare&#34;&gt;prepare&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;install docker by get-docker script.&lt;/li&gt;
&lt;li&gt;install compose by compose github install wiki&lt;/li&gt;
&lt;li&gt;install harbor by harbor wiki&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;lets-getting-ca&#34;&gt;lets getting CA&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;mkdir /data/harbor-cert &amp;amp; cd /data/harbor-cert&lt;/code&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;generate CA key&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;openssl genrsa -out ca.key 4096
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;CA crt&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;openssl req -x509 -new -nodes -sha512 -days 3650 \
-subj &amp;quot;/CN=yourdomain.com&amp;quot; \
-key ca.key \
-out ca.crt
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;lets-getting-server-certificate&#34;&gt;lets getting server certificate&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;server key&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;openssl genrsa -out yourdomain.com.key 4096
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Generate a Certificate Signing request&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;openssl req -sha512 -new \
-subj &amp;quot;/CN=yourdomain.com&amp;quot; \
-key yourdomain.com.key \
-out yourdomain.com.csr 
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Generate Certificate for Harbor:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cat &amp;gt; v3.ext &amp;lt;&amp;lt;-EOF
authorityKeyIdentifier=keyid,issuer
basicConstraints=CA:FALSE
keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment
extendedKeyUsage = serverAuth 
subjectAltName = @alt_names
[alt_names]
DNS.1=yourdomain.com
DNS.2=yourdomain
DNS.3=hostname
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;then:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;openssl x509 -req -sha512 -days 3650 \
-extfile v3.ext \
-CA ca.crt -CAkey ca.key -CAcreateserial \
-in yourdomain.com.csr \
-out yourdomain.com.crt
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;configure-harbor&#34;&gt;configure Harbor&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Convert server yourdomain.com.crt to yourdomain.com.cert:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;openssl x509 -inform PEM -in yourdomain.com.crt -out yourdomain.com.cert
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Delpoy yourdomain.com.cert, yourdomain.com.key, and ca.crt for Docker:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# if /etc/docker/certs.d/yourdomain.com/ not exist, mkdir.
cp yourdomain.com.cert /etc/docker/certs.d/yourdomain.com/
cp yourdomain.com.key /etc/docker/certs.d/yourdomain.com/
cp ca.crt /etc/docker/certs.d/yourdomain.com/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The following illustrates a configuration with custom certificates:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;/etc/docker/certs.d/
└── yourdomain.com:port   
   ├── yourdomain.com.cert  &amp;lt;-- Server certificate signed by CA
   ├── yourdomain.com.key   &amp;lt;-- Server key signed by CA
   └── ca.crt               &amp;lt;-- Certificate authority that signed the registry certificate
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Edit harbor.yml, add certificate, harbor.yml should be like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#set hostnamehostname: yourdomain.com
http:
port: 80
https:
# https port for harbor, default is 443
port: 443
# The path of cert and key files for nginx
certificate: /data/cert/yourdomain.com.crt
private_key: /data/cert/yourdomain.com.key
......
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Generate configuration files for Harbor:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose down -v # if harbor is running, down first, then run prepare script
./prepare
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Valid https&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Open browser, and open &lt;code&gt;https://yourdomain.com&lt;/code&gt;, see the harbor login page.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;docker login yourdomain.com&lt;/code&gt;  should success.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;ts&#34;&gt;TS&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;if use chrome open harbor, may have a &lt;strong&gt;NET::ERR_CERT_INVALID&lt;/strong&gt;. It is Chrome&amp;rsquo;s bug when visiting numerous top sites. Our self-signing certificate belonging this &lt;code&gt;numerous&lt;/code&gt; category. So, open harbor with firefox.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;if your docker has &lt;code&gt;Insecure Registries&lt;/code&gt; (you can see it by &lt;code&gt;docker ifno&lt;/code&gt;), add the harbor registry:(Centos7)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cat &amp;gt; /etc/docker/daemon.json &amp;lt;&amp;lt;-EOF
{
&amp;quot;insecure-registries&amp;quot; : [ &amp;quot;SGDLITVM0531.hpeswlab.net&amp;quot; ]
}
EOF
# then restart docker
systemctl daemon-reload
systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;I still dont know how to add insecure registry into docker on windos. I have tried install &lt;code&gt;ca.crt&lt;/code&gt;&amp;amp;&lt;code&gt;harbor.crt&lt;/code&gt; into &lt;code&gt;Trusted Root Certification&lt;/code&gt; and restart computer, still cannot connect the harbor.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;refer&#34;&gt;Refer&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://get.docker.com/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;get-docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/config/daemon/systemd/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;docker set proxy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/docker/compose/releases&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;compose wiki&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/goharbor/harbor/blob/master/docs/installation_guide.md&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;harbor install&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://appuals.com/fix-google-chrome-error-neterr_cert_invalid/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Chrome&amp;rsquo;s ssl bug&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/42211380/add-insecure-registry-to-docker&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;docker insecure registry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/registry/insecure/#windows&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;Windows docker insecure registry but failed&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Git Note</title>
      <link>https://leiheng.github.io/posts/tools/git-note/</link>
      <pubDate>Fri, 05 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://leiheng.github.io/posts/tools/git-note/</guid>
      <description>

&lt;h2 id=&#34;add-git&#34;&gt;Add git&lt;/h2&gt;

&lt;hr /&gt;

&lt;p&gt;创建并添加ssh key&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git config --global user.name &amp;quot;leiheng&amp;quot;
git config --global user.email &amp;quot;heng.lei@hpe.com&amp;quot;
ssh-keygen -t rsa -C &amp;quot;heng.lei@hpe.com&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;但是如果要在电脑上添加自己的github accout，refer &lt;a href=&#34;https://code.tutsplus.com/tutorials/quick-tip-how-to-work-with-github-and-multiple-accounts--net-22574&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;this&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ssh-add error&lt;/code&gt; refer &lt;a href=&#34;https://unix.stackexchange.com/questions/48863/ssh-add-complains-could-not-open-a-connection-to-your-authentication-agent/48868#48868&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;this&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;final: &lt;code&gt;git clone git@git-personal:leiheng\repo&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;final: &lt;code&gt;git clone git@github.com:leiheng\repo&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;配置了-gitignore-但是并没有起作用&#34;&gt;配置了&lt;code&gt;.gitignore&lt;/code&gt;但是并没有起作用&lt;/h2&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;method:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git rm --cached *.class
git commit -m &amp;quot;add gitignore file&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;good-habit&#34;&gt;Good Habit&lt;/h2&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;本地新建分支，然后merge到master上去，用master作为提pr的branch&lt;/li&gt;
&lt;li&gt;&lt;del&gt;开始写代码之前rebase代码&lt;/del&gt;

&lt;ul&gt;
&lt;li&gt;rebase before or after change does not matter, the point is, do not rebase branch which other guys or other mechine working on it.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;在add之前，看status&lt;code&gt;git status&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;在add之前，看diff &lt;code&gt;git diff&lt;/code&gt; 最好看diff是用&lt;strong&gt;source tree&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;注意&lt;strong&gt;编码&lt;/strong&gt;；github上是LF，win上是CRLF &lt;strong&gt;坑注意&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;can use &lt;code&gt;git option --help&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;rebase&#34;&gt;Rebase&lt;/h2&gt;

&lt;hr /&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git fetch upstream
//rebase branch which you want, most is default branch
// Do not rebase branch which other guy work on it
git rebase upstream/master
...
//if not use rebase, use pull also a good choice but cause a merge node created
git pull origin master
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;commit相关&#34;&gt;Commit相关&lt;/h2&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;前提&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;多个commit合并成一个commit(这些&amp;rsquo;多个commit&amp;rsquo;指只做一件事的commit)&lt;/li&gt;
&lt;li&gt;pr 尽可能的细&lt;/li&gt;
&lt;li&gt;一个pr，一个分支只能做一件事&lt;/li&gt;
&lt;li&gt;file change 最好不要超过10个&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git commit --amend --no-edit&lt;/code&gt; 补提交，但不增加commit 节点 &lt;strong&gt;love it&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git commit --amend&lt;/code&gt; change your commit msg&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git reset 某次commit的id
相当于
git reset --soft HEAD~
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;拉pr到本地分支&#34;&gt;拉pr到本地分支&lt;/h2&gt;

&lt;hr /&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git fetch origin pull/1941/head:repack-org-apache
git checkout repack-org-apache
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;在checkout之前不要手动创建这个&lt;code&gt;repack-org-apache&lt;/code&gt;分支
&lt;a href=&#34;https://www.huangyunkun.com/2018/06/15/pull-github-pr-to-local-branch/&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;refer&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;git-stash&#34;&gt;git stash&lt;/h2&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;git stash&lt;/li&gt;
&lt;li&gt;git stash apply&lt;/li&gt;
&lt;li&gt;git stash pop&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;submodule&#34;&gt;Submodule&lt;/h2&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;code&gt;git submodule add url folder&lt;/code&gt;
在一个module里面添加ignore的submodule，顺序是很重要的。
我在其中还看到了empty repo的一些特性。
1. submodule remote repo 不能为空
2. &lt;code&gt;.gitignore&lt;/code&gt; 必须在添加完 submodule 之后才能把这个 folder 添加上去，要是之前就添上去了咋搞，指路&lt;code&gt;git rm --cached&lt;/code&gt;
3. update submodule 指路 &lt;code&gt;git submodule --help&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;git-de-bug-bisect-https-git-scm-com-book-zh-v1-git-e5-b7-a5-e5-85-b7-e4-bd-bf-e7-94-a8-git-e8-b0-83-e8-af-95&#34;&gt;Git de-bug &lt;em&gt;bisect&lt;/em&gt;&lt;a href=&#34;https://git-scm.com/book/zh/v1/Git-%E5%B7%A5%E5%85%B7-%E4%BD%BF%E7%94%A8-Git-%E8%B0%83%E8%AF%95&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;!!!&lt;/a&gt;&lt;/h2&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;git bisect start&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git bisect bad&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git bisect good [good commit]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;find it and fixed. use &lt;code&gt;git bisect reset&lt;/code&gt; return the begin&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;remote-repo&#34;&gt;Remote repo&lt;/h2&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li&gt;remote repo 不能为空, empty repo cannot be created&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;refer&#34;&gt;REFER&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://git-scm.com/book/zh/v1/Git-%E5%B7%A5%E5%85%B7-%E5%82%A8%E8%97%8F%EF%BC%88Stashing%EF%BC%89&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;refer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://git-scm.com/book/zh/v1/Git-%E5%B7%A5%E5%85%B7-%E4%BD%BF%E7%94%A8-Git-%E8%B0%83%E8%AF%95&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;git bisect&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://git-scm.com/book/zh/v1/Git-%E5%B7%A5%E5%85%B7-%E5%AD%90%E6%A8%A1%E5%9D%97&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;submodule&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>